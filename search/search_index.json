{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my docs","text":"<p>A placeholder for knowledge and code snippets considered worth saving for future usage.</p> <p></p>"},{"location":"algo/arrays_data_structure/","title":"arrays data structure","text":"","tags":["arrays","data-structures","algo","frontend-masters"]},{"location":"algo/arrays_data_structure/#linear-search","title":"Linear Search","text":"<pre><code>func linearSearch(haystack []int, needle int) bool {\n  for _, v := range haystack {\n    if v == needle {\n      return true\n    }\n  }\n return false\n}\n</code></pre>","tags":["arrays","data-structures","algo","frontend-masters"]},{"location":"algo/arrays_data_structure/#binary-search-list","title":"Binary Search List","text":"<p>\u26a0\ufe0f hypothesis: the list must be sorted, ascending</p> <pre><code>func binarySearch(haystack []int, needle int) bool {\n  lo := 0\n  hi := len(haystack)\n  for lo &lt; hi {\n    m := lo + (hi - lo) / 2\n    v := haystack[m]\n    if v == needle {\n      return true\n    } else if needle &gt; v {\n      lo = m + 1\n    } else {\n      hi = m\n    }\n  }\n  return false\n}\n</code></pre>","tags":["arrays","data-structures","algo","frontend-masters"]},{"location":"algo/arrays_data_structure/#osqrtn-search","title":"O(\\(\\sqrt{N}\\)) search","text":"<p>Example use case :</p> <ul> <li> <p>given 2 crystal balls that will break if dropped from high enough distance, determine the exact spot in which it will break in the most optimized way</p> </li> <li> <p>binary search consideration : the fact that we have 2 balls, i.e meaning we could only have one single return true in the test v === needle. then the rest of the search tree will have to be linear search</p> </li> <li> <p>instead linear search by jumping square_root of N (length): on the 1st hit, a ball is lost, but we start back from that hi index minus square_root(N)</p> </li> </ul> <pre><code>func two_cristal_balls(breaks []bool) (v int) {\n  jumpAmout := int(math.Sqrt(float64(len(breaks))))\n  i := 0\n\n  // search jumping by N^1/2\n  for ; i &lt; len(breaks); i += jumpAmout {\n    if breaks[i] {\n    break\n    }\n  }\n\n  // then search linearly up to N^1/2 at most\n  i -= jumpAmout\n  for j := 0; j &lt; jumpAmout &amp;&amp; i &lt; len(breaks); j++ {\n      if breaks[i] {\n      return i\n    }\n    i++\n  }\n  return -1\n}\n</code></pre>","tags":["arrays","data-structures","algo","frontend-masters"]},{"location":"algo/linked_list/","title":"linked list","text":"","tags":["algo","linked-list"]},{"location":"algo/linked_list/#api-interface","title":"API interface","text":"<pre><code>interface LinkedList&lt;T&gt; {\n  get length(): number;\n  insertAt(item T, index: number): void;\n  remove(item T): T | undefined;\n  removeAt(index: number): T | undefined;\n  append(item: T): void;\n  prepend(iten: T): void;\n  get(index: number): T | undefined;\n}\n</code></pre>","tags":["algo","linked-list"]},{"location":"algo/queue/","title":"queue","text":"","tags":["algo","queue"]},{"location":"algo/queue/#queue-highlights","title":"Queue highlights","text":"","tags":["algo","queue"]},{"location":"algo/queue/#implementation","title":"Implementation","text":"<pre><code>package main\n\ntype Node[T any] struct {\n value T\n next  *Node[T]\n}\n\ntype Queue[T any] struct {\n head   *Node[T]\n tail   *Node[T]\n length int\n}\n\n// add one to the queue\nfunc (q *Queue[T]) Enqueue(v T) {\n  // \u2139\ufe0f  we maintain ourself the queue length\n  q.length++\n\n  n := &amp;Node[T]{value: v}\n  // case empty queue\n  if q.tail == nil {\n    q.head = n\n    q.tail = n\n    return\n  }\n\n  // \ud83d\ude4b be mindful of the order of the next lines\n  // point current tail next node to the new node\n  q.tail.next = n\n\n  // make the tail the new node\n  q.tail = n\n\n}\n\n// pop head\nfunc (q *Queue[T]) Deque() *T {\n if q.head == nil {\n  return nil\n }\n\n // \u2139\ufe0f  we maintain ourself the queue length\n q.length--\n\n // backup current head to v\n v := q.head\n\n // update head to next node\n q.head = q.head.next\n\n // cleanup (not necessary with GC)\n v.next = nil\n\n return &amp;v.value\n}\n\nfunc (q *Queue[T]) Peek() *T {\n if q.head == nil {\n  return nil\n }\n return &amp;q.head.value\n}\n</code></pre>","tags":["algo","queue"]},{"location":"algo/recursion/","title":"recursion","text":"<p>A function is composed of:</p> <pre><code>a) return address; the returned address make the recurse kind of 'bi directionnal':\n    with foo(5),\n    going down from 5 to 1,\n    then going up from 1 to 5\n    with the return address\n    this is highlighted when printing the n value\nb) a returned value\nc) arguments\n</code></pre> <p>Recurse steps/tools to keep in mind, because \"\ud83d\ude4b friends don't let friends recurse without the toolbox\":</p> <pre><code>1) pre\n2) recurse\n3) post (print again), optional\n</code></pre> <p>Always start implementing recursion with the base case, defining condition(s) to stop recursion.</p> <pre><code>func foo(n int) int {\n  // 1) Base case step\n if n == 1 {\n    fmt.Println(\"this is 1\")\n  return 1\n }\n\n  // 2) Pre step\n println(n)\n\n  // 3) Recurse step\n out := n + foo(n-1)\n\n  // 4) Post step\n println(n, \" again\")\n return out\n}\n\nfunc main(){\n  fmt.Println(foo(5))\n}\n</code></pre> <p>Prints:</p> <pre><code>5\n4\n3\n2\nthis is 1\n2  again\n3  again\n4  again\n5  again\n15\n</code></pre>"},{"location":"algo/stack/","title":"stack","text":"","tags":["algo","stack"]},{"location":"algo/stack/#stack-highlights","title":"Stack highlights","text":"","tags":["algo","stack"]},{"location":"algo/stack/#implementation","title":"Implementation","text":"<pre><code>class Node[T]:\n    def __init__(self, value: T) -&gt; None:\n        self.value: T = value\n        self.prev: Node[T] | None = None\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value}, {self.prev}\"\n\n\nclass Stack[T]:\n    def __init__(self) -&gt; None:\n        self.head: Node[T] | None = None\n        self.length: int = 0\n\n    def push(self, T) -&gt; None:\n        n = Node(T)\n\n        self.length += 1\n\n        if self.head is not None:\n            n.prev = self.head\n\n        self.head = n\n\n    def pop(self) -&gt; T | None:\n        if self.head is None:\n            return None\n\n        self.length -= 1\n\n        n = self.head\n        self.head = n.prev\n\n        return n.value\n\n    def peek(self) -&gt; T | None:\n        if not self.head:\n            return None\n        return self.head.value\n\n    def isEmpty(self) -&gt; bool:\n        return not self.length\n\nif __name__ == \"__main__\":\n    print(\"testing for \ud83d\udc1b\")\n    q = Stack[int]()\n    assert q.isEmpty() is True\n    assert q.head is None\n\n    q.push(1)\n    assert q.peek() == 1\n    assert q.length == 1\n    assert q.isEmpty() is False\n\n    q.push(2)\n    assert q.head is not None\n    assert q.head.value == 2\n\n    q.push(3)\n    assert q.head is not None\n    assert q.head.value == 3\n\n    print(f\"q.head: {q.head}\")\n\n    v = q.pop()\n    assert v == 3\n    assert q.length == 2\n\n    v = q.pop()\n    assert v == 2\n    assert q.length == 1\n\n    v = q.pop()\n    assert v == 1\n    assert q.length == 0\n    print(\"all good \ud83d\ude1c\")\n</code></pre>","tags":["algo","stack"]},{"location":"containers/platform/","title":"Platform","text":""},{"location":"containers/platform/#host-architectures","title":"Host Architectures","text":"<ul> <li>Docker containers aims to isolate an os running instance from your host os.</li> <li>It is widely used to develop applications that will be deployed on cloud infrastructure on linux os.</li> <li>One may think that developing on your localhost personal computer shall reproduce consistent behaviour on the image being deployed on the cloud. There is a one important thing to consider :</li> </ul> <p>The architecture of the host running the container</p> <p>If the host architecture [arch] is <code>amd64</code> (amd, intel processor), or <code>arm64</code> (raspberrypi, mac m1/m2) the underlying docker image used will be dependent of the host architecture you pull the image from.</p> <p>Consequences : you may experience docker image that cannot be built from a host, but possibly from another one for reasons such as <code>linux package and dependencies</code> being available for one arch, and not for the other.</p>"},{"location":"containers/platform/#how-to-mitigate","title":"How to mitigate","text":"<ul> <li>Consider building your image from a CICD runner with the same architecture of the end goal target architecture</li> <li>Develop directly on a cloud dev environment</li> </ul>"},{"location":"containers/platform/#image-manifest-architecture","title":"Image Manifest &amp; Architecture","text":"<ul> <li>On which platform (architecture + os) an image from a docker registry is available on :</li> </ul> <pre><code># example from docker hub registry:\ndocker manifest inspect nginx:latest\n</code></pre> <ul> <li>returns :</li> </ul> <pre><code>{\n   \"schemaVersion\": 2,\n   \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n   \"manifests\": [\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:06aa2038b42f1502b59b3a862b1f5980d3478063028d8e968f0810b9b0502380\",\n         \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:215352c0d3c37d4b7dd4e54b333755a6c7f85cde0e6286632c0daa5f92dc3f14\",\n         \"platform\": {\n            \"architecture\": \"arm\",\n            \"os\": \"linux\",\n            \"variant\": \"v5\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:ee28c54380d836869a4c6bbe1a825e649174fedc4c2bc281a6d3384bbd0fac4f\",\n         \"platform\": {\n            \"architecture\": \"arm\",\n            \"os\": \"linux\",\n            \"variant\": \"v7\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:5b35ed9fcfadf3750fb0e2b6a88913c5a7f84d8d1804c7c6fd6b79e35c071e8b\",\n         \"platform\": {\n            \"architecture\": \"arm64\",\n            \"os\": \"linux\",\n            \"variant\": \"v8\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:f63318b7ccc12e1fce241fdbf65c16ccee4c2e5bb48ac6ed468222c3590de6cf\",\n         \"platform\": {\n            \"architecture\": \"386\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:36b5efd39313d987f700a1996267d47fea871f872b3cea13e4cac9a4dc02d017\",\n         \"platform\": {\n            \"architecture\": \"mips64le\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:82b830dbef0567a4a5f5ba2e47ee8eab34485af6921310060aad72c0a34dd1f0\",\n         \"platform\": {\n            \"architecture\": \"ppc64le\",\n            \"os\": \"linux\"\n         }\n      },\n      {\n         \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n         \"size\": 1570,\n         \"digest\": \"sha256:e13e070adae8f92e90fc9975aec3946f4a8bff3ee048c108b9fcce18720c9d84\",\n         \"platform\": {\n            \"architecture\": \"s390x\",\n            \"os\": \"linux\"\n         }\n      }\n   ]\n}\n</code></pre>"},{"location":"containers/platform/#pull-image-architecture","title":"Pull image &amp; Architecture","text":"<p>When pulling an image, docker will pull the image corresponding to the platform the command is run on</p> <ul> <li>example on an intel/amd host architecture (amd64) :</li> </ul> <pre><code>docker pull nginx:latest\ndocker inspect nginx:latest\n</code></pre> <p>Line 87 indicates the image pulled is for architecture \"Architecture\": \"amd64\"</p> <pre><code>[\n    {\n        \"Id\": \"sha256:76c69feac34e85768b284f84416c3546b240e8cb4f68acbbe5ad261a8b36f39f\",\n        \"RepoTags\": [\n            \"nginx:latest\"\n        ],\n        \"RepoDigests\": [],\n        \"Parent\": \"\",\n        \"Comment\": \"\",\n        \"Created\": \"2022-10-25T10:23:08.612298023Z\",\n        \"Container\": \"783c85ff89f13f3b8df2f85ff9a8c0967600272c4da75f18023c75713d64785f\",\n        \"ContainerConfig\": {\n            \"Hostname\": \"783c85ff89f1\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.23.2\",\n                \"NJS_VERSION=0.7.7\",\n                \"PKG_RELEASE=1~bullseye\"\n            ],\n            \"Cmd\": [\n                \"/bin/sh\",\n                \"-c\",\n                \"#(nop) \",\n                \"CMD [\\\"nginx\\\" \\\"-g\\\" \\\"daemon off;\\\"]\"\n            ],\n            \"Image\": \"sha256:81d85638579047abdda2c2274af5961cb0e3c96c575171d0ff698f68f13e7b00\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"DockerVersion\": \"20.10.12\",\n        \"Author\": \"\",\n        \"Config\": {\n            \"Hostname\": \"\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.23.2\",\n                \"NJS_VERSION=0.7.7\",\n                \"PKG_RELEASE=1~bullseye\"\n            ],\n            \"Cmd\": [\n                \"nginx\",\n                \"-g\",\n                \"daemon off;\"\n            ],\n            \"Image\": \"sha256:81d85638579047abdda2c2274af5961cb0e3c96c575171d0ff698f68f13e7b00\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"Architecture\": \"amd64\",\n        \"Os\": \"linux\",\n        \"Size\": 141778201,\n        \"VirtualSize\": 141778201,\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/87557c711a0f2ccc048d343d830538047af6ba74b3bd1affbb803f4073766759/diff:/var/lib/docker/overlay2/5b060b75091d0f2c75b06ebe6a8579653ae252b2298d330a42032cf8e793feaa/diff:/var/lib/docker/overlay2/903ddff588bee8f67832558c597edc5c68c190cf0cab596b79b2560bb67dd36e/diff:/var/lib/docker/overlay2/889db9695e0b6e5b96d70b6d6af5d1b592a4fcc6070f5c5254b4815be5d087ca/diff:/var/lib/docker/overlay2/9af163b7a8f4150f2ecb7b862464d6d68ac8e8a3259c1a4b065f55fbfa2a5b3b/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/02aab637ed5c8fd748dea5b256bb68c224f1029e663516576391d80779f11055/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/02aab637ed5c8fd748dea5b256bb68c224f1029e663516576391d80779f11055/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/02aab637ed5c8fd748dea5b256bb68c224f1029e663516576391d80779f11055/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:a12586ed027fafddcddcc63b31671f406c25e43342479fc92a330e7e30d65f2e\",\n                \"sha256:e74d0d8d2defd5fff2f34af104d18e2512941fd9a6abb0581a6abcc95d7e90ee\",\n                \"sha256:2280b348f4d6af723032eec5a0c05f07222d6d10eafb5687eb2e86ca69de04fd\",\n                \"sha256:9e7119c28877f445e5893da11829e0aaa4e5b8112bf1521aebc4fd40219ddbae\",\n                \"sha256:4091cd312f19d65a309dd0962d374daf40f3f14b8c9e11538a6f250819c72801\",\n                \"sha256:a2e59a79fae0d350555b7143026eb0a6a55e31b0de877f6b202d5bde77b1e863\"\n            ]\n        },\n        \"Metadata\": {\n            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n        }\n    }\n]\n</code></pre> <p>NB : it is possible to pull an image for another platorm but experience so far indicates that even it you can build the image, you may face unexpected behaviour running you application, and this not advised.</p> <ul> <li>Example of command to pull image for a specific platorm :</li> </ul> <pre><code>docker pull --platform=linux/arm64 nginx:latest\n</code></pre>"},{"location":"database/postgresql/","title":"Postgresql","text":"","tags":["database","postgresql","postgres","pg","sql"]},{"location":"database/postgresql/#administration","title":"administration","text":"","tags":["database","postgresql","postgres","pg","sql"]},{"location":"database/postgresql/#union-caveats","title":"union caveats","text":"<ul> <li>multiple union with null as \"fieldName\" can lead to type mismatch.</li> <li>For instance consider:</li> </ul> <pre><code>select a as \"A\", null as \"D\" from table1\nunion\nselect null as \"A\", d as \"D\" from table2\n</code></pre> <ul> <li>with table1:</li> </ul> a b c int4 varchar boolean <ul> <li>with table2:</li> </ul> d e f numeric varchar bigint <p>\u26a0\ufe0f Problem: <code>null as</code> can be infered to the wrong type and union fails</p> <p>for instance <code>null as \"D\"</code> can be set to varchar whereas d from table2 is numeric</p> <p>\ud83d\udca1Solution: cast type using <code>null::&lt;type&gt;</code></p> <ul> <li>Query updated:</li> </ul> <pre><code>select a as \"A\", null::numeric as \"D\" from table1\nunion\nselect null::int4 as \"A\", d as \"D\" from table2\n</code></pre>","tags":["database","postgresql","postgres","pg","sql"]},{"location":"database/postgresql/#update-sequence","title":"update sequence","text":"<p>\ud83d\udcd6 case you need to update sequence when the following occurs: first create db schema, second import data</p> <p>\ud83e\udd14 more details ? Because the sequence created stayed at the initial values whereas the PK from data imported increased</p> <p>\ud83d\udca1 create a migration script to run after data import</p> <pre><code>setval 'sequence_name', (select max(id) + 1 from table_name);\n</code></pre> <p>\ud83e\udd14 why <code>+ 1</code> ? In case max returns 0, the query would fail. Hence add + 1 as safeguard</p> <p>rollback migration</p> <pre><code>alter sequence_name restart with 1;\n</code></pre>","tags":["database","postgresql","postgres","pg","sql"]},{"location":"database/postgresql/#dump-restore","title":"Dump &amp; Restore","text":"<p>locally from remote host with different pg version</p> <p>\ud83d\udcd6 key points :</p> <ul> <li>avoid running pg_dump on remote host and exposing filesystem usage at risk, specifically the running database</li> <li> <p>avoid installing on your local host a specific pg cli version</p> </li> <li> <p>dump:</p> </li> </ul> <pre><code>DATA=/data\ndocker run --rm -it \\\n    --network=\"host\" \\\n    -v $(pwd):$DATA \\\n    postgres:$PG_REMOTE_VERSION \\\n    pg_dump --verbose --host=$PG_HOST_FQDN --port=$PG_PORT --username=$PG_USER \\\n      --format=c --encoding=UTF-8 --no-privileges --no-owner --clean --create \\\n      --file $DATA/pg_dump.backup -n \"public\" $PG_DB\n</code></pre> <ul> <li>restore:</li> </ul> <pre><code>DATA=/data\ndocker run --rm -it \\\n    --network=\"host\" \\\n    -v $(pwd):$DATA \\\n    postgres:$PG_TARGET_VERSION \\\n    pg_restore --verbose --host=$PG_TARGET_HOST_FQDN --port=$PG_PORT --username=$PG_USER \\\n      --format=c  --no-privileges --no-owner --clean --dbname $PG_DB $DATA/pg_dump.backup\n</code></pre> <p>\u2139\ufe0f --create and --clean options are not compatible, either one of them for pg_restore</p>","tags":["database","postgresql","postgres","pg","sql"]},{"location":"golang/datatypes/maps/","title":"map","text":"","tags":["golang","map","datatype"]},{"location":"golang/datatypes/maps/#tips-and-tricks","title":"tips and tricks","text":"<ul> <li>when inserting key, values into a map remember, the final key order does not match the order of insertion</li> <li>if you need to keep an order, use a slice instead</li> </ul>","tags":["golang","map","datatype"]},{"location":"golang/pointers/tldr/","title":"pointers","text":"","tags":["go","golang","programming","pointers"]},{"location":"golang/pointers/tldr/#tldr","title":"tldr","text":"<p>All arguments are passed to function/methods by value, unless the argument explicitly takes a pointer</p> <p>Pointers can be nil</p>","tags":["go","golang","programming","pointers"]},{"location":"golang/testing/error/","title":"errors","text":"","tags":["go","golang","testing","errors","errcheck"]},{"location":"golang/testing/error/#unchecked-errors","title":"Unchecked errors","text":"<ul> <li>checks for unchecked errors in Go code</li> </ul> <pre><code>go install github.com/kisielk/errcheck@latest\n\n# inside directory\n\nerrcheck .\n</code></pre>","tags":["go","golang","testing","errors","errcheck"]},{"location":"golang/testing/helper/","title":"helper","text":"","tags":["go","golang","testing","helper","subtest"]},{"location":"golang/testing/helper/#helper","title":"helper","text":"<ul> <li>a helper function in a test file helps reuse code by marking it as a <code>helper</code>so that it is not considered by <code>go test</code></li> </ul> <pre><code>package main\n\nimport \"testing\"\n\nfunc assertOk (t testing.TB, got, want int){\n  t.Helper()\n\n  if got != want {\n      t.Fatalf(\"want %v, got %v\", want, got)\n  }\n}\n\nfunc TestFoo(t *testing.T) {\n  got:= Foo(10)\n  want:= 42\n\n  assertOk(t, got, want)\n}\n</code></pre>","tags":["go","golang","testing","helper","subtest"]},{"location":"golang/testing/helper/#subtest","title":"subtest","text":"<ul> <li>run a subtest of a function for clarity</li> </ul> <pre><code>package main\n\nimport \"testing\"\n\nfunc TestFoo(t *testing.T) {\n  assertOk:= func(t testing.TB, got, want int){\n    t.Helper()\n\n    if got != want {\n        t.Fatalf(\"want %v, got %v\", want, got)\n    }\n  }\n\n  t.Run(\"foo test case bar\", func(t *testing.T) {\n    got:= Foo(10)\n    want:= 42\n\n    assertOk(t, got, want)\n  }\n\n  t.Run(\"foo test case next\", func(t *testing.T) {\n    got:= Foo(100)\n    want:= 42\n\n    assertOk(t, got, want)\n  }\n}\n</code></pre>","tags":["go","golang","testing","helper","subtest"]},{"location":"kubernetes/calico/","title":"calico","text":"<p>Docs</p> <p>Installation using tigera operator:</p> <pre><code>kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml\n</code></pre> <p>Download the custom resources necessary to configure Calico:</p> <pre><code>curl https://raw.githubusercontent.com/projectcalico/calico/v3.29.2/manifests/custom-resources.yaml -O\n</code></pre> <p>Edit <code>custom-resources.yaml</code>:</p> <pre><code># This section includes base Calico installation configuration.\n# For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation\napiVersion: operator.tigera.io/v1\nkind: Installation\nmetadata:\n  name: default\nspec:\n  # Configures Calico networking.\n  calicoNetwork:\n    nodeAddressAutodetectionV4:\n      canReach: &lt;NETWORK-GATEWAY-IP&gt;      # \ud83d\udce2 change me\n    ipPools:\n    # # \u2139\ufe0f  default conf:\n    # - name: default-ipv4-ippool\n    #   blockSize: 26\n    #   cidr: 192.168.0.0/16\n    #   encapsulation: VXLANCrossSubnet\n    #   natOutgoing: Enabled\n    #   nodeSelector: all()\n\n---\n\n# This section configures the Calico API server.\n# For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer\napiVersion: operator.tigera.io/v1\nkind: APIServer\nmetadata:\n  name: default\nspec: {}\n</code></pre> <p>Create the manifest to install Calico.</p> <pre><code>kubectl create -f custom-resources.yaml\n</code></pre> <p>Verify Calico installation in your cluster:</p> <pre><code>watch kubectl get pods -n calico-system\n</code></pre>","tags":["kubernetes","calico"]},{"location":"kubernetes/calico/#encapsulation-types-in-calico","title":"Encapsulation Types in Calico","text":"<p>One of: IPIP, VXLAN, IPIPCrossSubnet, VXLANCrossSubnet, None</p> <ul> <li> <p>IPIP (Default for IPv4)</p> <p>Uses IP-in-IP (IPIP) encapsulation for all inter-node traffic.   Required when nodes are in different subnets without direct Layer 2 connectivity.   Pros: Low overhead, widely supported.   Cons: Adds some encapsulation overhead, may require kernel module support.</p> </li> <li> <p>VXLAN</p> <p>Uses VXLAN encapsulation for all inter-node traffic.   Works well in environments where IPIP is blocked or unsupported.   Suitable for cloud providers like AWS, GCP, and OpenStack.   Pros: More widely supported in cloud environments, allows for larger network scalability.   Cons: Higher overhead than IPIP.</p> </li> <li> <p>IPIPCrossSubnet</p> <p>Uses IPIP encapsulation only when nodes are in different subnets.   Directly routes traffic within the same subnet without encapsulation.   Use Case: Optimized for environments where nodes within the same subnet can communicate directly but need encapsulation across subnets.</p> </li> <li> <p>VXLANCrossSubnet</p> <p>Uses VXLAN encapsulation only when nodes are in different subnets.   Directly routes traffic within the same subnet.   Use Case: Similar to IPIPCrossSubnet, but uses VXLAN instead.</p> </li> <li> <p>None</p> <p>No encapsulation at all.   Requires direct L2 (Layer 2) connectivity between all nodes.   Use Case: Ideal for on-premises deployments with proper routing or BGP-based setups.</p> </li> </ul>","tags":["kubernetes","calico"]},{"location":"kubernetes/kube-vip/","title":"kube-vip","text":"<p>Provides a VIP address to ensure HA of control plane nodes, and load balancing for services</p>","tags":["kubernetes","kube-vip"]},{"location":"kubernetes/kube-vip/#use-with-kubeadm","title":"Use with kubeadm","text":"<p>docs static pod</p> <ul> <li>update <code>VIP-IP-Address</code> and run following command:</li> </ul> <pre><code>export VIP=&lt;VIP-IP-Address&gt;\nexport INTERFACE=eth0\nexport KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r \".[0].name\")\nalias kube-vip=\"docker run --network host --rm ghcr.io/kube-vip/kube-vip:$KVVERSION\"\n\nkube-vip manifest pod \\\n    --interface $INTERFACE \\\n    --address $VIP \\\n    --controlplane \\\n    --services \\\n    --arp \\\n    --leaderElection &gt; kube-vip.yaml\n</code></pre> <p>Copy kube-vip.yaml on all masters : <code>/etc/kubernetes/manifest/kube-vip.yaml</code>.</p> <p>\ud83d\udce2 : for the 1st kubeadm init, the vip must be configure once : <code>ip addr add &lt;IP-VIP&gt;/32 dev &lt;INTERFACE&gt;</code></p>","tags":["kubernetes","kube-vip"]},{"location":"kubernetes/kubeadm/","title":"kubernetes","text":"<ul> <li>Disclaimer</li> <li>Post OS install</li> <li>Network configuration</li> <li>CGroup</li> <li>KubeletConfiguration</li> <li>Container Runtime</li> <li>runc</li> <li>CNI plugins</li> <li>containerd config</li> <li>CRICTL</li> <li>Kubeadm</li> <li>Prereq<ul> <li>Firewall</li> <li>Swap</li> </ul> </li> <li>packages</li> <li>control plane</li> <li>kubeadm init</li> <li>Kube VIP</li> <li>Calico</li> <li>PKI certificates and requirements</li> <li>Distributing Self-Signed Certificates</li> <li>Nodes DNS</li> <li>Join</li> <li>Worker node</li> </ul>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#disclaimer","title":"Disclaimer","text":"<p>Creating a kubernetes cluster on arm64 server using kubeadm may leave few resources left for application to run.</p> <p>This documentation should mostly be considered as training/tutorial man pages.</p> <p><code>k3s</code> kubernetes cluster may be preferred (faster setup and less resources used by k8s cluster) if you're willing to spin up a cluster quickly on arm64, and deploying application on it.</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#post-os-install","title":"Post OS install","text":"<pre><code>sudo dpkg-configure locales\nsudo hostnamectl set-hostname &lt;NODE-FQDN&gt;\n</code></pre> <p>docs </p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#network-configuration","title":"Network configuration","text":"<p>Enable IPv4 packet forwarding</p> <pre><code># sysctl params required by setup, params persist across reboots\ncat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_forward = 1\nEOF\n\n# Apply sysctl params without reboot\nsudo sysctl --system\n\n# Verify that net.ipv4.ip_forward is set to 1 with:\nsysctl net.ipv4.ip_forward\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#cgroup","title":"CGroup","text":"<p>Control Groups are used to constrain resources allocated to processes Used by kubelet and container runtime to enforce resource management</p> <p>~cgroupfs driver~ -&gt; systemd cgroup driver, as it is recommended when systemd is the ini system</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#kubeletconfiguration","title":"KubeletConfiguration","text":"<p>This need to be added to kubelet configuration in kubeadm init conf file. Check this section</p> <pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\nfailSwapOn: false\nmemorySwap:\n  swapBehavior: LimitedSwap\n</code></pre> <p>cgroup may not be active by default on arm64 os</p> <pre><code>sudo vim /boot/firmware/cmdline.txt\n</code></pre> <p>\u26a0\ufe0f  Do NOT add line breaks ! This file should remain a single line \u26a0\ufe0f</p> <p>Add at the end of the line the following:</p> <pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 cgroup_enable=hugetlb\n</code></pre> <pre><code>sudo reboot\n# check\ncat /proc/mounts |grep cgroup\n# cgroup2 /sys/fs/cgroup cgroup2 rw,nosuid,nodev,noexec,relatime 0 0\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#container-runtime","title":"Container Runtime","text":"<p>\ud83d\udce2 Using systemd for cgroup driver enforce using systemd for the CRI</p> <p>docs</p> <pre><code># pick up a containerd-&lt;VERSION&gt;-&lt;OS&gt;-&lt;ARCH&gt;.tar.gz\nwget https://github.com/containerd/containerd/releases/download/v2.0.2/containerd-2.0.2-linux-arm64.tar.gz\n\nwget https://github.com/containerd/containerd/releases/download/v2.0.2/containerd-2.0.2-linux-arm64.tar.gz.sha256sum\n\n# check\nsha256sum -c containerd-2.0.2-linux-arm64.tar.gz.sha256sum\n# containerd-2.0.2-linux-arm64.tar.gz: OK\n\nsudo tar Cxzvf /usr/local containerd-2.0.2-linux-arm64.tar.gz\n</code></pre> <p>to start containerd via systemd, you should also download the containerd.service</p> <pre><code>wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service\nsudo mkdir -p /usr/local/lib/systemd/system/\nsudo mv containerd.service /usr/local/lib/systemd/system/\n\nsudo systemctl daemon-reload\nsudo systemctl enable --now containerd\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#runc","title":"runc","text":"<p>docs</p> <pre><code># pick a release from https://github.com/opencontainers/runc/releases\nwget https://github.com/opencontainers/runc/releases/download/v1.2.4/runc.arm64\nsudo install -m 755 runc.arm64 /usr/local/sbin/runc\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#cni-plugins","title":"CNI plugins","text":"<p>docs</p> <pre><code># pick a release from  https://github.com/containernetworking/plugins/releases\nwget https://github.com/containernetworking/plugins/releases/download/v1.6.2/cni-plugins-linux-arm64-v1.6.2.tgz\n# sha256sum\nwget https://github.com/containernetworking/plugins/releases/download/v1.6.2/cni-plugins-linux-arm64-v1.6.2.tgz.sha256\n\nsha256sum -c cni-plugins-linux-arm64-v1.6.2.tgz.sha256\n# cni-plugins-linux-arm64-v1.6.2.tgz: OK\n\nsudo mkdir -p /opt/cni/bin\nsudo tar Cxzvf /opt/cni/bin cni-plugins-linux-arm64-v1.6.2.tgz\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#containerd-config","title":"containerd config","text":"<p>Save the default configuration in <code>/etc/containerd/config.toml</code>:</p> <pre><code>sudo mkdir /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n</code></pre> <p>add the following to ensure the CRI is handled by systemd</p> <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n  ...\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n    SystemdCgroup = true\n</code></pre> <pre><code>sudo systemctl restart containerd.service\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#crictl","title":"CRICTL","text":"<p>CLI and validation tools for Kubelet Container Runtime Interface (CRI) .</p> <p>install docs</p> <pre><code>VERSION=\"v1.32.0\"\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-arm64.tar.gz\nsudo tar zxvf crictl-$VERSION-linux-arm64.tar.gz -C /usr/local/bin\nrm -f crictl-$VERSION-linux-arm64.tar.gz\n</code></pre> <p>file : <code>/etc/crictl.yaml</code></p> <pre><code>runtime-endpoint: unix:///var/run/containerd/containerd.sock\nimage-endpoint: unix:///var/run/containerd/containerd.sock\ntimeout: 10\ndebug: false\npull-image-on-create: false\n</code></pre> <p>usage docs</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#kubeadm","title":"Kubeadm","text":"<p>docs</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#prereq","title":"Prereq","text":"","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#firewall","title":"Firewall","text":"<pre><code>sudo apt install netcat-openbsd dnsutils\n# listen on port\nnc -l 6443 &amp;\n# check port opened\nnc -zv 127.0.0.1 6443\n</code></pre> <p>Full list of ports to be opened : docs</p> <p>if necessary enable and start <code>nftables.service</code> to configure the least permissive firewall settings</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#swap","title":"Swap","text":"<ul> <li>If possible disable swap, <code>sudo swapoff -a</code></li> </ul> <pre><code>- Identify configured swap devices and files with cat /proc/swaps.\n- Turn off all swap devices and files with swapoff -a.\n- Remove any matching reference found in /etc/fstab.\n- Optional: Destroy any swap devices or files found in step 1 to prevent their reuse.\nDue to your concerns about leaking sensitive information, you may wish to consider\nperforming some sort of secure wipe.\n</code></pre> <ul> <li>Otherwise tolerate swap :</li> <li><code>NodeSwap</code> must be enabled on the kubelet</li> <li><code>failSwapOn: false</code> in kubelet configuration</li> </ul> <p>\u2753 kubelet configuration</p> <pre><code>memorySwap:\n  swapBehavior: LimitedSwap\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#packages","title":"packages","text":"<p>kubeadm, kubelet, kubectl</p> <ul> <li>kubelet and kubeadm version should match</li> <li>kubelet &lt;= any kube-apiserver</li> <li>kube-apiserver in HA cluster : 1 minor version skew max</li> <li>3 minor version skew max than kube-apiserver &lt; kube-proxy &lt;= kube-apiserver</li> </ul> <p>kubeadm creates etcd is in <code>/var/lib/etcd</code>. should be backed-up</p> <pre><code>sudo apt-get update\n# apt-transport-https may be a dummy package; if so, you can skip that package\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n# If the directory `/etc/apt/keyrings` does not exist,\n# it should be created before the curl command, read the note below.\n# sudo mkdir -p -m 755 /etc/apt/keyrings\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list\necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n\nsudo systemctl enable --now kubelet\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#control-plane","title":"control plane","text":"<p>To upgrade a single control-plane kubeadm cluster to high availability you should specify the <code>--control-plane-endpoint</code> to set the shared endpoint for all control-plane nodes.</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#kubeadm-init","title":"kubeadm init","text":"<pre><code>kubeadm config print init-defaults\n</code></pre> <ul> <li>kubeadm configuration migration : <code>kubeadm config migrate</code>:</li> </ul> <pre><code>apiVersion: kubeadm.k8s.io/v1beta4\nkind: InitConfiguration\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef  # \ud83d\udce2 replace this\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nlocalAPIEndpoint:\n  advertiseAddress: &lt;IP-Node&gt;     # \ud83d\udce2 change me\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  imagePullSerial: true\n  name: &lt;Node-Hostname&gt;           # \ud83d\udce2 change me\n  taints: null\ntimeouts:\n  controlPlaneComponentHealthCheck: 4m0s\n  discovery: 5m0s\n  etcdAPICall: 2m0s\n  kubeletHealthCheck: 4m0s\n  kubernetesAPICall: 1m0s\n  tlsBootstrap: 5m0s\n  upgradeManifests: 5m0s\n---\napiVersion: kubeadm.k8s.io/v1beta4\nkind: ClusterConfiguration\ncaCertificateValidityPeriod: 87600h0m0s\ncertificateValidityPeriod: 8760h0m0s\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\nencryptionAlgorithm: RSA-2048\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.k8s.io\nkubernetesVersion: 1.32.0\ncontrolPlaneEndpoint: \"&lt;KUBE-VIP-HOST:6443\" # \ud83d\udce2 change me\nnetworking:\n  dnsDomain: cluster.local        # \ud83d\udce2 change me\n  # ~serviceSubnet: 10.96.0.0/12~\n  serviceSubnet: 10.116.0.0/16    # \ud83d\udca1 update serviceSubnet and add podSubnet\n  podSubnet: 10.117.0.0/16\n\nproxy: {}\napiServer: {}\nscheduler: {}\n</code></pre> <ul> <li>append the custom config for the kubelet configuration:</li> </ul> <pre><code>kind: KubeletConfiguration\napiVersion: kubelet.config.k8s.io/v1beta1\ncgroupDriver: systemd\nfailSwapOn: false\nmemorySwap:\n  swapBehavior: LimitedSwap\n</code></pre> <ul> <li>upload this config <code>init-config-m1.yaml</code> into the 1st control plane node</li> </ul> <p>\ud83d\udce2 the kube-vip cannot be used at 1st start, hence the ip must be temporarily assigned to the network interface  of the node :</p> <pre><code>sudo ip add &lt;KUBE-VIP-IP&gt; dev &lt;interface-name&gt; # eth0 for instance, do ip link to check\n</code></pre> <ul> <li>then run init :</li> </ul> <pre><code>sudo kubeadm init --config init-config-m1.yaml --upload-certs\n</code></pre> <p>\ud83d\udd25 Troubleshoot:</p> <pre><code>sudo kubeadm reset\nsudo systemctl stop kubelet.service\n# update the node setup (config, etc...)\n# then run kubeadmn init command again \u2708\ufe0f\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#pki-certificates-and-requirements","title":"PKI certificates and requirements","text":"<p>best-practices gen certs</p> <p>Authentication over TLS : kubeadm can provide them auto, or generate your own certificates in order not to store them on the API server</p> <p>Certificate requirements:</p> <ul> <li>Server certificates:</li> <li>for the API server endpoint</li> <li>for the etcd server</li> <li>for each kubelet</li> <li> <p>optional for the front-proxy</p> </li> <li> <p>Client certificates:</p> </li> <li>for  each kubelet, to auth to the API server as a client of the k8s API</li> <li>for each API server, used to authenticate to etcd</li> <li>control manager to securely communicate with the API server</li> <li>scheduler to securely communicate with the API server</li> <li>for each node, for kube-proxy to auth to the API server</li> <li>optional for admins to auth to the API server</li> <li> <p>optional for the front-proxy</p> </li> <li> <p>storage :  <code>/etc/kubernetes/pki</code></p> </li> </ul>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#distributing-self-signed-certificates","title":"Distributing Self-Signed Certificates","text":"<p>A client node may refuse to recognize a self-signed CA certificate as valid. For a non-production deployment, or for a deployment that runs behind a company firewall, you can distribute a self-signed CA certificate to all clients and refresh the local list for valid certificates.</p> <pre><code>sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt\nsudo update-ca-certificates\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#nodes-dns","title":"Nodes DNS","text":"<p>On arm64, NetworkManager service may be used to configure <code>/etc/resolv.conf</code> file.</p> <ul> <li>to manually configure the dns:</li> </ul> <p><code>sudo vim /etc/NetworkManager/NetworkManager.conf</code></p> <pre><code>[main]\ndns=none\n</code></pre> <pre><code>sudo systemctl restart NetworkManager.service\n</code></pre> <ul> <li>now the file /etc/resolv.conf is empty, edit the file to your preferences (add a dns server)</li> <li>when rebooting networking, the <code>/etc/resolv.conf</code> file will stay as reconfigured</li> </ul>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#join","title":"Join","text":"","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#worker-node","title":"Worker node","text":"<pre><code>kubeadm join &lt;CLUSTER-DOMAIN&gt;:6443 --config &lt;join-config.yaml&gt;\n</code></pre> <ul> <li>example join config:</li> </ul> <pre><code>apiVersion: kubeadm.k8s.io/v1beta4\ncaCertPath: /etc/kubernetes/pki/ca.crt\ndiscovery:\n  bootstrapToken:\n    apiServerEndpoint: &lt;CLUSTER-DOMAIN&gt;:6443   # \ud83d\udce2 change me\n    caCertHashes:\n    - sha256:****                              # \ud83d\udce2 change me\n    token: ****                                # \ud83d\udce2 change me\n  tlsBootstrapToken: ****                      # \ud83d\udce2 change me\nkind: JoinConfiguration\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  imagePullSerial: true\n  name: &lt;NODE-FQDN&gt;                            # \ud83d\udce2 change me\n  taints: null\ntimeouts:\n  controlPlaneComponentHealthCheck: 4m0s\n  discovery: 5m0s\n  etcdAPICall: 2m0s\n  kubeletHealthCheck: 4m0s\n  kubernetesAPICall: 1m0s\n  tlsBootstrap: 5m0s\n  upgradeManifests: 5m0s\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#kube-vip","title":"Kube VIP","text":"<p>Doc: kube-vip</p>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#calico","title":"Calico","text":"<p>Doc: calico</p> <p>\ud83d\udd25 Troubleshoot:</p> <ul> <li>check logs of the operator in namespace <code>tigera-operator</code></li> </ul>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#nodes-taint","title":"Nodes taint","text":"<p>\u26a0\ufe0f  Taints are mostly handled by kubernetes, so most of the time it should not be configured manually</p> <ul> <li>Nodes taints are handled by labels <code>node-role/kubernetes.io/...</code>, visible with a <code>kubectl describe nodes &lt;node-name&gt;</code></li> <li>check <code>kubectl taint --help</code>, particularly for possible effects (NoSchedule, NoExecute (evict running pods), PreferNoSchedule)</li> </ul> <pre><code># Add a taint, though set auto by the control plane\nkubectl taint nodes &lt;node-name&gt; node.kubernetes.io/not-ready:NoExecute\n# NOTE: this one tells to not schedule workload (application) on this node,\n# you must add a toleration on the pods manifest to allow it to be scheduled \n# on this control-plane node (typcaly for system pods)\nkubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/control-plane:NoSchedule\nkubectl taint nodes &lt;node-name&gt; node.kubernetes.io/not-ready:NoSchedule\n# Remove a taint with '-' at the end\nkubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/...:NoSchedule-\n</code></pre>","tags":["bare-metal","arm64"]},{"location":"kubernetes/kubeadm/#node-notready","title":"Node NotReady","text":"<ul> <li>describe pods, <code>Conditions Type</code> might indicate valuable information, such as error with the CRI =&gt; restart service containerd</li> </ul>","tags":["bare-metal","arm64"]},{"location":"network/protocol/","title":"protocols","text":"","tags":["network","sftp"]},{"location":"network/protocol/#sftp","title":"sftp","text":"","tags":["network","sftp"]},{"location":"network/protocol/#chroot-jail","title":"chroot jail","text":"<ul> <li>restrict user/group to specific directory</li> </ul>","tags":["network","sftp"]},{"location":"network/protocol/#how-to","title":"how to","text":"<ul> <li>update <code>sshd_config</code></li> </ul> <pre><code>Match group sftp\n  ChrootDirectory /home/sftp\n  X11Forwarding no\n  AllowTcpForwarding no\n  ForceCommand internal-sftp\n</code></pre> <ul> <li>filesystem ownership :</li> <li>/home/sftp root:root, chmod 755</li> <li>/home/sftp/* root:sftp, chmod 755 for readonly access</li> </ul>","tags":["network","sftp"]},{"location":"network/socat/","title":"socat","text":"","tags":["network"]},{"location":"network/socat/#usage","title":"usage","text":"<pre><code>socat TCP4-LISTEN:8022,fork TCP4:upstreamhost:8022\n</code></pre> <ul> <li>listen locahost port 8022</li> <li>send trafic to upstreamhost:8022</li> </ul>","tags":["network"]},{"location":"python/builtin-modules/iterools/","title":"Itertools","text":"In\u00a0[2]: Copied! <pre>from itertools import chain, repeat, cycle\n</pre> from itertools import chain, repeat, cycle In\u00a0[3]: Copied! <pre>lines = [\"a\", \"b\", \"c\"]\ncol = [1, 2, 3]\n</pre> lines = [\"a\", \"b\", \"c\"] col = [1, 2, 3] In\u00a0[4]: Copied! <pre>for c in chain.from_iterable(zip(lines, col)):\n    print(c)\n</pre> for c in chain.from_iterable(zip(lines, col)):     print(c) <pre>a\n1\nb\n2\nc\n3\n</pre> In\u00a0[5]: Copied! <pre>for i in zip(repeat(\"H\"), col):\n    print(i)\n</pre> for i in zip(repeat(\"H\"), col):     print(i) <pre>('H', 1)\n('H', 2)\n('H', 3)\n</pre> In\u00a0[6]: Copied! <pre>for i in zip(cycle(\"abc\"), col):\n    print(i)\n</pre> for i in zip(cycle(\"abc\"), col):     print(i) <pre>('a', 1)\n('b', 2)\n('c', 3)\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"python/builtin-modules/iterools/#itertools","title":"Itertools\u00b6","text":""},{"location":"python/builtin-modules/iterools/#chain","title":"Chain\u00b6","text":""},{"location":"python/builtin-modules/iterools/#repeat","title":"Repeat\u00b6","text":""},{"location":"python/builtin-modules/iterools/#cycle","title":"Cycle\u00b6","text":""},{"location":"python/database/sqlalchemy/","title":"Sqlalchemy","text":"","tags":["database","python","orm"]},{"location":"python/database/sqlalchemy/#intro-with-sqllite","title":"Intro with sqllite","text":"<p>Intro to sqlalchemy using plain text sql, and builtin functions : db-notebook repository</p>","tags":["database","python","orm"]},{"location":"python/functions/arguments/","title":"Function arguments","text":""},{"location":"python/functions/arguments/#how-are-they-passed-to-function","title":"How are they passed to function","text":"<p>All arguments are passed to function/methods by reference</p> <p>BUT</p> <ul> <li>if the argument is immutable. Any modification of the argument in the function will create a new object under the function scope, that will not be reflected outside the function scope</li> <li>if the argument is mutable, as expected, any modification of the argument inside the function will be reflected outside the function scope</li> </ul>"},{"location":"python/functions/arguments/#immutable-built-in-types","title":"Immutable built-in types","text":"<ul> <li>str</li> <li>int</li> <li>float</li> <li>tuple</li> </ul>"},{"location":"python/functions/arguments/#mutable-built-in-types","title":"Mutable built-in types","text":"<ul> <li>list</li> <li>dict</li> <li>set</li> </ul>"},{"location":"python/testing/unit/pytest/","title":"Pytest","text":"","tags":["python","test","unit test","pytest","mock","pytest-mock"]},{"location":"python/testing/unit/pytest/#pytest-mock","title":"pytest-mock","text":"<p>Usage example of the <code>pytest_mock</code> module</p>","tags":["python","test","unit test","pytest","mock","pytest-mock"]},{"location":"python/testing/unit/pytest/#mock-object-method","title":"Mock object method","text":"<pre><code>from pytest_mock import MockerFixture\n\nclass A:\n    def echo(self, text: str):\n        fmt_text = text.upper()\n        return fmt_text\n\n\ndef test_foo(mocker: MockerFixture):\n    a = A()\n    mocker.patch.object(a, 'echo', return_value=\"MOCKED\", autospec=True)\n    assert a.echo(\"hello\") == \"MOCKED\"\n\n\ndef test_foo_no_mock():\n    a = A()\n    assert a.echo(\"hello\") == \"HELLO\"\n</code></pre>","tags":["python","test","unit test","pytest","mock","pytest-mock"]},{"location":"python/testing/unit/pytest/#mock-module-function","title":"Mock module function","text":"<ul> <li>my_package.my_module file :</li> </ul> <pre><code>def my_function_to_mock(text: str):\n    return text.capitalize()\n\ndef function_using_function_to_mock(text: str):\n    use: str = my_function_to_mock(text)\n    return use + \" Function\"\n</code></pre> <ul> <li>testing :</li> </ul> <pre><code>from pytest_mock import MockerFixture\nfrom my_package.my_module import function_using_function_to_mock\n\ndef test_function_using_function_to_mock(mocker: MockerFixture):\n    mocker.patch(\"my_package.my_module.my_function_to_mock\", return_value=\"MOCKED\")\n    actual = function_using_function_to_mock(\"hello\")\n    assert actual == \"MOCKED Function\"\n\ndef test_function_without_mocking(mocker: MockerFixture):\n    actual = function_using_function_to_mock(\"hello\")\n    assert actual == \"Hello Function\"\n</code></pre>","tags":["python","test","unit test","pytest","mock","pytest-mock"]},{"location":"python/web/api/throttle/","title":"Throttle api calls","text":"","tags":["python","api","api call","api rate limit","asyncio","asyncio throttle"]},{"location":"python/web/api/throttle/#api-request-limit","title":"API Request Limit","text":"<p>Usage example of the <code>asyncio_throttle</code> module that can be useful to overcome api rate limit</p> <p>this example also display a good way to use async http requests by providing asyncio a task list</p> <pre><code>import asyncio\nimport time\nfrom asyncio_throttle.throttler import Throttler\n\n\nasync def wait_s(i: int, throttler: Throttler):\n    async with throttler:\n        await asyncio.sleep(1) # (1)\n        print(f\"{time.time()} : {i} done\")\n\nasync def tasks(throttler: Throttler):\n    t = [asyncio.create_task(wait_s(i, throttler)) for i in range(200)]\n    await asyncio.wait(t, timeout=None, return_when=asyncio.ALL_COMPLETED)\n\nasync def main():\n    # for a rate limit of 5 requests / sec :\n    t = Throttler(rate_limit=5, period=1)\n    await tasks(t)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li> make an http request here instead ;)</li> </ol>","tags":["python","api","api call","api rate limit","asyncio","asyncio throttle"]}]}